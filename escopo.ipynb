{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração de dados com Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados do corpo HTML salvos em 'ans_body_content.html'.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.gov.br/ans/pt-br/acesso-a-informacao/participacao-da-sociedade/atualizacao-do-rol-de-procedimentos\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()  # Verifica erros na requisição\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "#Extrair o conteúdo do corpo (body)\n",
    "    body_content = soup.find(\"body\")\n",
    "\n",
    "#Salvar em um arquivo para análise (opcional)\n",
    "    with open(\"ans_body_content.html\", \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(str(body_content))\n",
    "\n",
    "    print(\"Dados do corpo HTML salvos em 'ans_body_content.html'.\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Erro ao acessar o site: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Link encontrado: https://www.gov.br/ans/pt-br/acesso-a-informacao/participacao-da-sociedade/atualizacao-do-rol-de-procedimentos/Anexo_I_Rol_2021RN_465.2021_RN627L.2024.pdf\n",
      "✅ PDF baixado com sucesso como: Anexo_I.pdf\n",
      "🔗 Link encontrado: https://www.gov.br/ans/pt-br/acesso-a-informacao/participacao-da-sociedade/atualizacao-do-rol-de-procedimentos/Anexo_II_DUT_2021_RN_465.2021_RN628.2025_RN629.2025.pdf\n",
      "✅ PDF baixado com sucesso como: Anexo_II.pdf\n"
     ]
    }
   ],
   "source": [
    "link_pdf1 = None\n",
    "link_pdf2 = None\n",
    "\n",
    "for a in soup.find_all('a', href=True):\n",
    "    href = a['href']\n",
    "    if not href.endswith('.pdf'):\n",
    "        continue\n",
    "    \n",
    "    if 'Anexo_I' in href and link_pdf1 is None:\n",
    "        link_pdf1 = href\n",
    "    \n",
    "    if 'Anexo_II' in href and link_pdf2 is None:\n",
    "        link_pdf2 = href\n",
    "\n",
    "    if link_pdf1 and link_pdf2:\n",
    "        break\n",
    "\n",
    "# Baixar o PDF, se encontrado\n",
    "if link_pdf1:\n",
    "    nome_arquivo = \"Anexo_I.pdf\"\n",
    "    # Caso o link seja relativo, adiciona o domínio\n",
    "    if not link_pdf1.startswith('http'):\n",
    "        link_pdf1 = \"https://www.gov.br\" + link_pdf1\n",
    "\n",
    "    print(f\"🔗 Link encontrado: {link_pdf1}\")\n",
    "    pdf_response = requests.get(link_pdf1)\n",
    "    with open(nome_arquivo, 'wb') as f:\n",
    "        f.write(pdf_response.content)\n",
    "    print(f\"✅ PDF baixado com sucesso como: {nome_arquivo}\")\n",
    "else:\n",
    "    print(\"❌ Link do Anexo I não encontrado.\")\n",
    "\n",
    "\n",
    "\n",
    "if link_pdf2:\n",
    "    nome_arquivo2 = \"Anexo_II.pdf\"\n",
    "        #Caso o link seja relativo, adiciona o domínio\n",
    "    if not link_pdf2.startswith('http'):\n",
    "        link_pdf2 = \"https://www.gov.br\" + link_pdf2\n",
    "\n",
    "    print(f\"🔗 Link encontrado: {link_pdf2}\")\n",
    "    pdf_response = requests.get(link_pdf2)\n",
    "    with open(nome_arquivo2, 'wb') as f:\n",
    "        f.write(pdf_response.content)\n",
    "    print(f\"✅ PDF baixado com sucesso como: {nome_arquivo2}\")\n",
    "else:\n",
    "    print(\"❌ Link do Anexo II não encontrado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Arquivo ZIP criado com sucesso: Anexos.zip\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# Compacta os dois arquivos em um ZIP\n",
    "zip_path = \"Anexos.zip\"\n",
    "with ZipFile(zip_path, 'w') as zipf:\n",
    "    zipf.write('./Anexo_I.pdf', arcname=\"Anexo_I.pdf\")\n",
    "    zipf.write('./Anexo_II.pdf', arcname=\"Anexo_II.pdf\")\n",
    "\n",
    "print(f\"✅ Arquivo ZIP criado com sucesso: {zip_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformação de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo tabelas do PDF...\n"
     ]
    },
    {
     "ename": "JVMNotFoundException",
     "evalue": "No JVM shared library file (jvm.dll) found. Try setting up the JAVA_HOME environment variable properly.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJVMNotFoundException\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# 2.1 Extração de todas as tabelas do PDF\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLendo tabelas do PDF...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m tabelas = \u001b[43mread_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPDF_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpages\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m3-181\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultiple_tables\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlattice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# 2.2 Juntar todas em uma tabela única\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mConcatenando dados...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tabula\\io.py:400\u001b[39m, in \u001b[36mread_pdf\u001b[39m\u001b[34m(input_path, output_format, encoding, java_options, pandas_options, multiple_tables, user_agent, use_raw_url, pages, guess, area, relative_area, lattice, stream, password, silent, columns, relative_columns, format, batch, output_path, force_subprocess, options)\u001b[39m\n\u001b[32m    397\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is empty. Check the file, or download it manually.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     output = \u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtabula_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjava_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_subprocess\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_subprocess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    408\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m temporary:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tabula\\io.py:74\u001b[39m, in \u001b[36m_run\u001b[39m\u001b[34m(options, java_options, path, encoding, force_subprocess)\u001b[39m\n\u001b[32m     69\u001b[39m     _tabula_vm = SubprocessTabula(\n\u001b[32m     70\u001b[39m         java_options=java_options, silent=options.silent, encoding=encoding\n\u001b[32m     71\u001b[39m     )\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _tabula_vm:\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     _tabula_vm = \u001b[43mTabulaVm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjava_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjava_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _tabula_vm \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _tabula_vm.tabula:\n\u001b[32m     76\u001b[39m         _tabula_vm = SubprocessTabula(\n\u001b[32m     77\u001b[39m             java_options=java_options, silent=options.silent, encoding=encoding\n\u001b[32m     78\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tabula\\backend.py:45\u001b[39m, in \u001b[36mTabulaVm.__init__\u001b[39m\u001b[34m(self, java_options, silent)\u001b[39m\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m silent:\n\u001b[32m     37\u001b[39m         java_options.extend(\n\u001b[32m     38\u001b[39m             (\n\u001b[32m     39\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m-Dorg.slf4j.simpleLogger.defaultLogLevel=off\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     42\u001b[39m             )\n\u001b[32m     43\u001b[39m         )\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[43mjpype\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstartJVM\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mjava_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvertStrings\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjava\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlang\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlang\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtechnology\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtabula\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtabula\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\jpype\\_core.py:267\u001b[39m, in \u001b[36mstartJVM\u001b[39m\u001b[34m(jvmpath, classpath, ignoreUnrecognized, convertStrings, interrupt, *jvmargs)\u001b[39m\n\u001b[32m    264\u001b[39m         jvm_args = jvm_args[\u001b[32m1\u001b[39m:]\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m jvmpath:\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m     jvmpath = \u001b[43mgetDefaultJVMPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    269\u001b[39m     \u001b[38;5;66;03m# Allow the path to be a PathLike.\u001b[39;00m\n\u001b[32m    270\u001b[39m     jvmpath = os.fspath(jvmpath)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\jpype\\_jvmfinder.py:70\u001b[39m, in \u001b[36mgetDefaultJVMPath\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     69\u001b[39m     finder = LinuxJVMFinder()\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfinder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_jvm_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\jpype\\_jvmfinder.py:204\u001b[39m, in \u001b[36mJVMFinder.get_jvm_path\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m jvm_notsupport_ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m jvm_notsupport_ext\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m JVMNotFoundException(\u001b[33m\"\u001b[39m\u001b[33mNo JVM shared library file (\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    205\u001b[39m                            \u001b[33m\"\u001b[39m\u001b[33mfound. Try setting up the JAVA_HOME \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    206\u001b[39m                            \u001b[33m\"\u001b[39m\u001b[33menvironment variable properly.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    207\u001b[39m                            .format(\u001b[38;5;28mself\u001b[39m._libfile))\n",
      "\u001b[31mJVMNotFoundException\u001b[39m: No JVM shared library file (jvm.dll) found. Try setting up the JAVA_HOME environment variable properly."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "from tabula import read_pdf\n",
    "\n",
    "# Nome do arquivo PDF e do resultado\n",
    "PDF_PATH = \"Anexo_I.pdf\"\n",
    "CSV_PATH = \"procedimentos.csv\"\n",
    "ZIP_PATH = \"Teste_Lucas_Jaensen_Daros.zip\"\n",
    "\n",
    "# 2.1 Extração de todas as tabelas do PDF\n",
    "print(\"Lendo tabelas do PDF...\")\n",
    "tabelas = read_pdf(PDF_PATH, pages='3-181', multiple_tables=True, lattice=True)\n",
    "\n",
    "# 2.2 Juntar todas em uma tabela única\n",
    "print(\"Concatenando dados...\")\n",
    "df_completo = pd.concat(tabelas, ignore_index=True)\n",
    "\n",
    "# 2.4 Substituir abreviações OD e AMB (ajuste conforme o nome das colunas)\n",
    "colunas = df_completo.columns\n",
    "\n",
    "#df_completo.head()\n",
    "display(df_completo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_completo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mdf_completo\u001b[49m.columns))\n",
      "\u001b[31mNameError\u001b[39m: name 'df_completo' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(df_completo.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvando CSV...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 2.2 Salvar CSV\n",
    "print(\"Salvando CSV...\")\n",
    "df_completo.to_csv(CSV_PATH, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compactando CSV em zip...\n",
      "Arquivo gerado: Teste_Lucas_Jaensen_Daros.zip\n"
     ]
    }
   ],
   "source": [
    "# 2.3 Compactar o CSV em um .zip\n",
    "print(\"Compactando CSV em zip...\")\n",
    "with zipfile.ZipFile(ZIP_PATH, 'w') as zipf:\n",
    "    zipf.write(CSV_PATH)\n",
    "\n",
    "print(f\"Arquivo gerado: {ZIP_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectar colunas com OD e AMB, assumindo que estão nos nomes\n",
    "for col in colunas:\n",
    "    df_completo[col] = df_completo[col].replace('OD', 'Seg. Odontológico')\n",
    "    df_completo[col] = df_completo[col].replace('AMB', 'Seg. Ambulatorial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_completo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m display(\u001b[43mdf_completo\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_completo' is not defined"
     ]
    }
   ],
   "source": [
    "display(df_completo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste Banco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Lendo arquivo: 1T2023.csv\n",
      "✅ Dados de '1T2023.csv' inseridos com sucesso.\n",
      "📂 Lendo arquivo: 1T2024.csv\n",
      "✅ Dados de '1T2024.csv' inseridos com sucesso.\n",
      "📂 Lendo arquivo: 2t2023.csv\n",
      "✅ Dados de '2t2023.csv' inseridos com sucesso.\n",
      "📂 Lendo arquivo: 2T2024.csv\n",
      "✅ Dados de '2T2024.csv' inseridos com sucesso.\n",
      "📂 Lendo arquivo: 3T2023.csv\n",
      "✅ Dados de '3T2023.csv' inseridos com sucesso.\n",
      "📂 Lendo arquivo: 3T2024.csv\n",
      "✅ Dados de '3T2024.csv' inseridos com sucesso.\n",
      "📂 Lendo arquivo: 4T2023.csv\n",
      "✅ Dados de '4T2023.csv' inseridos com sucesso.\n",
      "📂 Lendo arquivo: 4T2024.csv\n",
      "✅ Dados de '4T2024.csv' inseridos com sucesso.\n",
      "\n",
      "🏁 Importação finalizada.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "\n",
    "# 1. Caminho da pasta com os CSVs\n",
    "pasta_csvs = \"c:/Users/Lucas/Desktop/1T2024\"\n",
    "\n",
    "# 2. Conexão com o PostgreSQL\n",
    "usuario = \"postgres\"\n",
    "senha = \"postgres\"\n",
    "host = \"localhost\"\n",
    "porta = \"5432\"\n",
    "banco = \"postgres\"\n",
    "\n",
    "# 3. Cria a engine de conexão\n",
    "conexao = f\"postgresql://{usuario}:{senha}@{host}:{porta}/{banco}\"\n",
    "engine = create_engine(conexao)\n",
    "\n",
    "# 4. Loop para ler e importar todos os CSVs\n",
    "for arquivo in os.listdir(pasta_csvs):\n",
    "    if arquivo.lower().endswith('.csv'):\n",
    "        caminho_csv = os.path.join(pasta_csvs, arquivo)\n",
    "        print(f\"📂 Lendo arquivo: {arquivo}\")\n",
    "\n",
    "        try:\n",
    "            # Leitura do CSV com encoding correto\n",
    "            df = pd.read_csv(caminho_csv, sep=';', encoding='latin1')\n",
    "\n",
    "            # Renomear colunas\n",
    "            df.rename(columns={\n",
    "                'DATA': 'data_registro',\n",
    "                'REG_ANS': 'reg_ans',\n",
    "                'CD_CONTA_CONTABIL': 'cd_contabeis',\n",
    "                'DESCRICAO': 'descricao',\n",
    "                'VL_SALDO_INICIAL': 'vl_saldo_inicial',\n",
    "                'VL_SALDO_FINAL': 'vl_saldo_final'\n",
    "            }, inplace=True)\n",
    "\n",
    "            # Converter números e corrigir encoding de texto\n",
    "            df['vl_saldo_inicial'] = df['vl_saldo_inicial'].astype(str).str.replace(',', '.').astype(float)\n",
    "            df['vl_saldo_final'] = df['vl_saldo_final'].astype(str).str.replace(',', '.').astype(float)\n",
    "            df['descricao'] = df['descricao'].apply(\n",
    "                lambda x: x.encode('latin1').decode('utf-8') if isinstance(x, str) else x\n",
    "            )\n",
    "\n",
    "            # Envia para o banco\n",
    "            df.to_sql(\"contabeis\", engine, if_exists=\"append\", index=False)\n",
    "            print(f\"✅ Dados de '{arquivo}' inseridos com sucesso.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erro ao processar '{arquivo}': {e}\")\n",
    "\n",
    "print(\"\\n🏁 Importação finalizada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lucas\\AppData\\Local\\Temp\\ipykernel_20728\\1118479709.py:20: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df['Data_Registro_ANS'] = pd.to_datetime(df['Data_Registro_ANS'], errors='coerce', dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dados importados com sucesso para a tabela 'operadoras'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Caminho do CSV\n",
    "csv_path = \"c:/Users/Lucas/Desktop/Relatorio_cadop.csv\"  # usar / ou raw string\n",
    "\n",
    "# Conexão PostgreSQL\n",
    "usuario = \"postgres\"\n",
    "senha = \"postgres\"\n",
    "host = \"localhost\"\n",
    "porta = \"5432\"\n",
    "banco = \"postgres\"\n",
    "\n",
    "engine = create_engine(f\"postgresql://{usuario}:{senha}@{host}:{porta}/{banco}\")\n",
    "\n",
    "# Leitura do CSV\n",
    "df = pd.read_csv(csv_path, sep=';', encoding='latin1')\n",
    "\n",
    "# Converter datas\n",
    "df['Data_Registro_ANS'] = pd.to_datetime(df['Data_Registro_ANS'], errors='coerce', dayfirst=True)\n",
    "\n",
    "# Renomear colunas para coincidir com o banco\n",
    "df.columns = [\n",
    "    'registro_ans', 'cnpj', 'razao_social', 'nome_fantasia', 'modalidade',\n",
    "    'logradouro', 'numero', 'complemento', 'bairro', 'cidade', 'uf', 'cep',\n",
    "    'ddd', 'telefone', 'fax', 'endereco_eletronico', 'representante',\n",
    "    'cargo_representante', 'regiao_de_comercializacao', 'data_registro_ans'\n",
    "]\n",
    "\n",
    "# Corrigir codificação de todas as colunas do tipo objeto (texto)\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    df[col] = df[col].apply(\n",
    "        lambda x: x.encode('latin1').decode('utf-8') if isinstance(x, str) else x\n",
    "    )\n",
    "\n",
    "# Inserir no banco\n",
    "df.to_sql(\"operadoras\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "print(\"✅ Dados importados com sucesso para a tabela 'operadoras'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.11.2, pytest-8.3.5, pluggy-1.5.0\n",
      "rootdir: Z:\\home\\lucasjd\\Projetos\\IntuitiveCare\n",
      "collected 4 items\n",
      "\n",
      "tests\\test_teste_banco.py \u001b[31mE\u001b[0m\u001b[31mE\u001b[0m\u001b[31m                                             [ 50%]\u001b[0m\n",
      "tests\\test_transformacao_de_dados.py \u001b[31mF\u001b[0m\u001b[31m                                   [ 75%]\u001b[0m\n",
      "tests\\test_web_scraping.py \u001b[32m.\u001b[0m\u001b[31m                                             [100%]\u001b[0m\n",
      "\n",
      "=================================== ERRORS ====================================\n",
      "\u001b[31m\u001b[1m_______________ ERROR at setup of test_importar_csvs_contabeis ________________\u001b[0m\n",
      "file Z:\\home\\lucasjd\\Projetos\\IntuitiveCare\\tests\\test_teste_banco.py, line 19\n",
      "  def test_importar_csvs_contabeis(engine):\n",
      "\u001b[31mE       fixture 'engine' not found\u001b[0m\n",
      "\u001b[31m>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\u001b[0m\n",
      "\u001b[31m>       use 'pytest --fixtures [testpath]' for help on them.\u001b[0m\n",
      "\n",
      "Z:\\home\\lucasjd\\Projetos\\IntuitiveCare\\tests\\test_teste_banco.py:19\n",
      "\u001b[31m\u001b[1m_________________ ERROR at setup of test_importar_operadoras __________________\u001b[0m\n",
      "file Z:\\home\\lucasjd\\Projetos\\IntuitiveCare\\tests\\test_teste_banco.py, line 32\n",
      "  def test_importar_operadoras(engine):\n",
      "\u001b[31mE       fixture 'engine' not found\u001b[0m\n",
      "\u001b[31m>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\u001b[0m\n",
      "\u001b[31m>       use 'pytest --fixtures [testpath]' for help on them.\u001b[0m\n",
      "\n",
      "Z:\\home\\lucasjd\\Projetos\\IntuitiveCare\\tests\\test_teste_banco.py:32\n",
      "================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m____________________________ test_csv_zip_gerados _____________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_csv_zip_gerados\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      ">       extrair_procedimentos_para_csv_zip()\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests\\test_transformacao_de_dados.py\u001b[0m:5: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\u001b[1m\u001b[31mtransformação_de_dados.py\u001b[0m:21: in extrair_procedimentos_para_csv_zip\n",
      "    \u001b[0mtabelas = read_pdf(caminho_pdf, pages=paginas, multiple_tables=\u001b[94mTrue\u001b[39;49;00m, lattice=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tabula\\io.py\u001b[0m:400: in read_pdf\n",
      "    \u001b[0moutput = _run(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tabula\\io.py\u001b[0m:74: in _run\n",
      "    \u001b[0m_tabula_vm = TabulaVm(java_options=java_options, silent=options.silent)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tabula\\backend.py\u001b[0m:45: in __init__\n",
      "    \u001b[0mjpype.startJVM(*java_options, convertStrings=\u001b[94mFalse\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\jpype\\_core.py\u001b[0m:267: in startJVM\n",
      "    \u001b[0mjvmpath = getDefaultJVMPath()\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mC:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\jpype\\_jvmfinder.py\u001b[0m:70: in getDefaultJVMPath\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m finder.get_jvm_path()\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "self = <jpype._jvmfinder.WindowsJVMFinder object at 0x0000019EB4A21FD0>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mget_jvm_path\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Retrieves the path to the default or first found JVM library\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Returns:\u001b[39;49;00m\n",
      "    \u001b[33m        The path to the JVM shared library file\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Raises:\u001b[39;49;00m\n",
      "    \u001b[33m        ValueError: No JVM library found or No Support JVM found\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        jvm_notsupport_ext = \u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mfor\u001b[39;49;00m method \u001b[95min\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._methods:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mtry\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                jvm = method()\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# If found check the architecture\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m jvm:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[96mself\u001b[39;49;00m.check(jvm)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mexcept\u001b[39;49;00m \u001b[96mNotImplementedError\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Ignore missing implementations\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mpass\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mexcept\u001b[39;49;00m JVMNotFoundException:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[90m# Ignore not successful methods\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mpass\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mexcept\u001b[39;49;00m JVMNotSupportedException \u001b[94mas\u001b[39;49;00m e:\u001b[90m\u001b[39;49;00m\n",
      "                jvm_notsupport_ext = e\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94melse\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                \u001b[94mif\u001b[39;49;00m jvm \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "                    \u001b[94mreturn\u001b[39;49;00m jvm\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m jvm_notsupport_ext \u001b[95mis\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mraise\u001b[39;49;00m jvm_notsupport_ext\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mraise\u001b[39;49;00m JVMNotFoundException(\u001b[33m\"\u001b[39;49;00m\u001b[33mNo JVM shared library file (\u001b[39;49;00m\u001b[33m{0}\u001b[39;49;00m\u001b[33m) \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                                   \u001b[33m\"\u001b[39;49;00m\u001b[33mfound. Try setting up the JAVA_HOME \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                                   \u001b[33m\"\u001b[39;49;00m\u001b[33menvironment variable properly.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                                   .format(\u001b[96mself\u001b[39;49;00m._libfile))\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       jpype._jvmfinder.JVMNotFoundException: No JVM shared library file (jvm.dll) found. Try setting up the JAVA_HOME environment variable properly.\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\Lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\jpype\\_jvmfinder.py\u001b[0m:204: JVMNotFoundException\n",
      "---------------------------- Captured stdout call -----------------------------\n",
      "📄 Lendo tabelas do PDF...\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ===========================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m tests/test_transformacao_de_dados.py::\u001b[1mtest_csv_zip_gerados\u001b[0m - jpype._jvmfinder.JVMNotFoundException: No JVM shared library file (jvm.dll)...\n",
      "\u001b[31mERROR\u001b[0m tests/test_teste_banco.py::\u001b[1mtest_importar_csvs_contabeis\u001b[0m\n",
      "\u001b[31mERROR\u001b[0m tests/test_teste_banco.py::\u001b[1mtest_importar_operadoras\u001b[0m\n",
      "\u001b[31m==================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m1 passed\u001b[0m, \u001b[31m\u001b[1m2 errors\u001b[0m\u001b[31m in 8.62s\u001b[0m\u001b[31m ====================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
